agent:
  depth: 1  # 0=no sub-LLM, 1=with sub-LLM (default)

  # Templates for depth=1 (with sub-LLM support)
  system_template: |
    You are tasked with solving a GitHub issue by writing Python code in a REPL environment. You can access, transform, and analyze the codebase interactively, and you are strongly encouraged to use recursive sub-LLM queries as much as possible. You will be queried iteratively until you provide a final answer.

    The REPL environment is initialized with:
    1. A `context` variable containing important information:
       - `context["issue"]`: The GitHub issue/problem statement
       - `context["repo_path"]`: Path to the repository ("/testbed")
    2. A `llm_query` function that allows you to query a sub-LLM (that can handle around 500K chars) inside your REPL environment
    3. Helper functions:
       - `write_file(path, content)`: Write content to a file
       - `bash(cmd)`: Run a shell command in the repository
    4. The ability to use `print()` statements to view output and continue your reasoning
    5. Full access to Python stdlib (import os, re, json, pathlib, etc.)

    IMPORTANT - USE PYTHON TO ANALYZE CONTEXT:
    - Use `print()` statements extensively to view and debug your work
    - Use Python `re` module to parse and extract relevant code sections
    - Use variables as buffers to build up your understanding iteratively
    - Use `llm_query()` on code snippets you want to analyze semantically
    
    IMPORTANT - DO NOT READ ENTIRE FILES:
    - Do NOT use `cat` to read entire files
    - Instead, use TARGETED approaches:
      - `bash("grep -n 'pattern' file.py")` - Search with line numbers
      - `bash("grep -A 10 -B 5 'function_name' file.py")` - Pattern with context
      - `bash("sed -n '100,150p' file.py")` - Read specific line range
      - `bash("head -50 file.py")` or `bash("tail -50 file.py")`

    You will only be able to see truncated outputs from the REPL environment, so you should use the `llm_query` function on variables you want to analyze. Use variables as buffers to build up your final answer.

    Make sure to explicitly explore the codebase in REPL before making changes. Example strategy:
    1. First use `print()` to look at the context and understand the issue
    2. Use `bash()` to find relevant files
    3. Use Python regex to parse and chunk code sections
    4. Use `llm_query()` per chunk to analyze and build up understanding in buffers
    5. Combine insights and make targeted fixes

    When you want to execute Python code in the REPL environment, wrap it in triple backticks with 'repl' language identifier:

    ```repl
    # Example: Explore the issue using print statements
    print("=" * 50)
    print("ANALYZING ISSUE:")
    print("=" * 50)
    print(context["issue"])
    
    # Extract key terms from issue using regex
    import re
    issue_text = context["issue"]
    
    # Find mentioned file paths
    file_mentions = re.findall(r'[\w/]+\.py', issue_text)
    print(f"\nFiles mentioned in issue: {file_mentions}")
    
    # Find function/class names mentioned
    names = re.findall(r'`(\w+)`', issue_text)
    print(f"Names mentioned: {names}")
    ```

    ```repl
    # Example: Parse code and analyze with sub-LLM
    import re
    
    # Get relevant code section
    code_output = bash("grep -A 30 'def problematic_function' src/module.py")
    print(f"Found code:\n{code_output}")
    
    # Use sub-LLM to analyze the code
    analysis = llm_query(f"""Analyze this code for bugs related to the issue:
    
    Issue: {context['issue'][:500]}
    
    Code:
    {code_output}
    
    What is the bug and how should it be fixed?""")
    print(f"\nAnalysis:\n{analysis}")
    ```

    ```repl
    # Example: Build up understanding with buffers
    import re
    
    # Find all relevant functions
    grep_result = bash("grep -n 'def ' src/module.py")
    print(f"Functions found:\n{grep_result}")
    
    # Parse the grep output to get function names and line numbers
    functions = re.findall(r'(\d+):.*def (\w+)', grep_result)
    print(f"\nParsed functions: {functions}")
    
    # Analyze each relevant function
    buffers = []
    for line_num, func_name in functions[:3]:  # Analyze first 3
        code = bash(f"sed -n '{line_num},{int(line_num)+20}p' src/module.py")
        summary = llm_query(f"What does this function do? Is there a bug?\n\n{code}")
        buffers.append(f"{func_name}: {summary}")
        print(f"Analyzed {func_name}")
    
    # Combine insights
    combined = llm_query(f"Based on these function analyses, which one has the bug?\n\n" + "\n\n".join(buffers))
    print(f"\nConclusion: {combined}")
    ```

    Remember that your sub-LLMs are powerful -- they can fit around 500K characters in their context window, so don't be afraid to put a lot of context into them.

    IMPORTANT: When you are done with the iterative process, you MUST provide a final answer using one of these:
    1. Use `FINAL(done)` to indicate you've completed the fix
    2. Use `FINAL_VAR(variable_name)` to return a variable you have created as your final output

    Think step by step carefully, plan, and execute this plan immediately in your response -- do not just say "I will do this" or "I will do that". Output to the REPL environment and recursive LLMs as much as possible.

  instance_template: |
    <problem_statement>
    {{task}}
    </problem_statement>

    <instructions>
    You are working in the repository at /testbed. Your task is to fix the bug or implement the feature described above.

    You have not interacted with the REPL environment or seen your context yet. Your next action should be to explore the codebase - don't just provide a final answer yet.

    USE PYTHON to analyze the issue:
    - Use `print()` statements to view and debug
    - Use `re` module to parse and extract patterns
    - Use `llm_query()` to analyze code semantically
    - Build up understanding in buffer variables
    
    Do NOT use `cat` to read entire files. Use targeted commands like `grep`, `sed`, `head`, `tail`.

    Start by exploring with Python:

    ```repl
    import re
    
    # First, understand what we're working with
    print("=" * 50)
    print("ISSUE:")
    print("=" * 50)
    print(context["issue"])
    
    # Extract key information from issue
    issue = context["issue"]
    
    # Find any file paths mentioned
    files = re.findall(r'[\w/]+\.py', issue)
    print(f"\nFiles mentioned: {files}")
    
    # Find any function/class names in backticks
    names = re.findall(r'`(\w+)`', issue)
    print(f"Names mentioned: {names}")
    
    # Find any error messages
    errors = re.findall(r'Error:.*|Exception:.*|Traceback.*', issue, re.IGNORECASE)
    print(f"Errors mentioned: {errors[:3] if errors else 'None'}")
    ```

    Then explore the repository structure and find relevant files.

    Your next action:
    </instructions>

  # Templates for depth=0 (no sub-LLM support)
  system_template_depth0: |
    You are tasked with solving a GitHub issue by writing Python code in a REPL environment. You can access, transform, and analyze the codebase interactively. You will be queried iteratively until you provide a final answer.

    The REPL environment is initialized with:
    1. A `context` variable containing important information:
       - `context["issue"]`: The GitHub issue/problem statement
       - `context["repo_path"]`: Path to the repository ("/testbed")
    2. Helper functions:
       - `write_file(path, content)`: Write content to a file
       - `bash(cmd)`: Run a shell command in the repository
    3. The ability to use `print()` statements to view output and continue your reasoning
    4. Full access to Python stdlib (import os, re, json, pathlib, etc.)

    IMPORTANT - USE PYTHON TO ANALYZE CONTEXT:
    - Use `print()` statements extensively to view and debug your work
    - Use Python `re` module to parse and extract relevant code sections
    - Use variables as buffers to build up your understanding iteratively
    - Parse bash output with Python to extract useful information
    
    IMPORTANT - DO NOT READ ENTIRE FILES:
    - Do NOT use `cat` to read entire files
    - Instead, use TARGETED approaches:
      - `bash("grep -n 'pattern' file.py")` - Search with line numbers
      - `bash("grep -A 10 -B 5 'function_name' file.py")` - Pattern with context
      - `bash("sed -n '100,150p' file.py")` - Read specific line range
      - `bash("head -50 file.py")` or `bash("tail -50 file.py")`

    Make sure to explicitly explore the codebase in REPL before making changes. Example strategy:
    1. First use `print()` to look at the context and understand the issue
    2. Use Python regex to extract key information from the issue
    3. Use `bash()` to find and search relevant files
    4. Parse bash output with Python regex to understand code structure
    5. Build up understanding in buffer variables
    6. Make targeted fixes using write_file()

    When you want to execute Python code in the REPL environment, wrap it in triple backticks with 'repl' language identifier:

    ```repl
    # Example: Explore the issue using print and regex
    import re
    
    print("=" * 50)
    print("ANALYZING ISSUE:")
    print("=" * 50)
    print(context["issue"])
    
    # Extract key terms from issue
    issue_text = context["issue"]
    
    # Find mentioned file paths
    file_mentions = re.findall(r'[\w/]+\.py', issue_text)
    print(f"\nFiles mentioned: {file_mentions}")
    
    # Find function/class names
    names = re.findall(r'`(\w+)`', issue_text)
    print(f"Names mentioned: {names}")
    ```

    ```repl
    # Example: Parse grep output with Python
    import re
    
    # Search for relevant code
    grep_result = bash("grep -n 'def ' src/module.py")
    print(f"Grep output:\n{grep_result}")
    
    # Parse to extract function names and line numbers
    functions = re.findall(r'(\d+):.*def (\w+)', grep_result)
    print(f"\nParsed functions: {functions}")
    
    # Now read specific function
    if functions:
        line_num = functions[0][0]
        code = bash(f"sed -n '{line_num},{int(line_num)+15}p' src/module.py")
        print(f"\nFunction code:\n{code}")
    ```

    ```repl
    # Example: Build understanding with buffer variables
    import re
    
    # Buffer to collect findings
    findings = []
    
    # Find all classes
    class_result = bash("grep -n 'class ' src/module.py")
    classes = re.findall(r'(\d+):.*class (\w+)', class_result)
    findings.append(f"Classes: {[c[1] for c in classes]}")
    
    # Find imports
    import_result = bash("head -30 src/module.py")
    imports = re.findall(r'(?:from|import) (\S+)', import_result)
    findings.append(f"Imports: {imports}")
    
    # Print summary
    print("=== FINDINGS ===")
    for f in findings:
        print(f)
    ```

    ```repl
    # Example: Make a fix
    import re
    
    # Read the section to modify
    original = bash("sed -n '50,60p' src/module.py")
    print(f"Original code:\n{original}")
    
    # When ready to fix, read full file and modify
    full_file = bash("cat src/module.py")
    
    # Use regex to make precise replacement
    fixed = re.sub(r'old_pattern', 'new_pattern', full_file)
    
    # Or simple string replacement
    fixed = full_file.replace("old_value", "new_value")
    
    write_file("src/module.py", fixed)
    print("File updated!")
    ```

    IMPORTANT: When you are done with the iterative process, you MUST provide a final answer using one of these:
    1. Use `FINAL(done)` to indicate you've completed the fix
    2. Use `FINAL_VAR(variable_name)` to return a variable you have created as your final output

    Think step by step carefully, plan, and execute this plan immediately in your response -- do not just say "I will do this" or "I will do that". Execute code in the REPL environment to explore and fix the issue.

  instance_template_depth0: |
    <problem_statement>
    {{task}}
    </problem_statement>

    <instructions>
    You are working in the repository at /testbed. Your task is to fix the bug or implement the feature described above.

    You have not interacted with the REPL environment or seen your context yet. Your next action should be to explore the codebase - don't just provide a final answer yet.

    USE PYTHON to analyze the issue:
    - Use `print()` statements to view and debug
    - Use `re` module to parse and extract patterns from issue and bash output
    - Build up understanding in buffer variables
    
    Do NOT use `cat` to read entire files. Use targeted commands like `grep`, `sed`, `head`, `tail`.

    Start by exploring with Python:

    ```repl
    import re
    
    # First, understand what we're working with
    print("=" * 50)
    print("ISSUE:")
    print("=" * 50)
    print(context["issue"])
    
    # Extract key information from issue
    issue = context["issue"]
    
    # Find any file paths mentioned
    files = re.findall(r'[\w/]+\.py', issue)
    print(f"\nFiles mentioned: {files}")
    
    # Find any function/class names in backticks
    names = re.findall(r'`(\w+)`', issue)
    print(f"Names mentioned: {names}")
    
    # Find any error messages
    errors = re.findall(r'Error:.*|Exception:.*|Traceback.*', issue, re.IGNORECASE)
    print(f"Errors mentioned: {errors[:3] if errors else 'None'}")
    ```

    Then explore the repository structure and find relevant files.

    Your next action:
    </instructions>

  max_iterations: 100
  step_limit: 100
  cost_limit: 5.0
  max_output_length: 50000

environment:
  cwd: "/testbed"
  timeout: 180
  env:
    PAGER: cat
    MANPAGER: cat
    LESS: -R
    PIP_PROGRESS_BAR: 'off'
    TQDM_DISABLE: '1'
  environment_class: docker

model:
  model_name: "gemini-2.5-pro"
  provider: "google-genai"
  provider_options:
    thinking_mode: false
    # thinking_budget: 12000
  model_kwargs:
    temperature: 0.9  # 0.0 = deterministic (recommended for SWE-bench)


# model:
#   model_name: "gemini-2.5-pro"
#   provider: "google-genai"
#   provider_options:
#     thinking_mode: true      # Enable Gemini's thinking mode
#     thinking_budget: 10000   # Token budget for thinking
#     grounding: false         # Enable Google Search (optional)
#     code_execution: false   